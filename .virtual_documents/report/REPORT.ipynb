


import pandas as pd
from IPython.display import Image






df = pd.read_csv("../data/processed/clean_data.csv")
df.describe()[["total_cholesterol"]]





Image("../figures/eda/hist_targets.png")


Image("../figures/eda/hist_all_features.png")


Image("../figures/eda/boxplot_total_cholesterol.png")





Image("../figures/eda/univariate_total_cholesterol.png")


Image("../figures/eda/correlation_heatmap.png")











Image("../figures/evaluation/residuals_total_cholesterol.png")
Image("../figures/predictions/true_vs_predicted_total_cholesterol.png")






Image("../figures/feature_importance/feature_importance_xgboost_total_cholesterol.png")
Image("../figures/feature_importance/feature_importance_rf_total_cholesterol.png")












# Load final model performance metrics
#train_metrics = pd.read_csv("../summaries/train_metrics.csv")
#test_metrics = pd.read_csv("../summaries/test_metrics.csv")
train_metrics = pd.read_csv("../tableau/train_metrics.csv")
test_metrics = pd.read_csv("../tableau/test_metrics.csv")

train_metrics["Dataset"] = "Train"
test_metrics["Dataset"] = "Test"
results_df = pd.concat([train_metrics, test_metrics], ignore_index=True)

display(results_df)



# --- Helper to lighten a color ---
def lighten(color, factor=0.4):
    r, g, b = to_rgb(color)
    return (1 - factor) * r + factor, (1 - factor) * g + factor, (1 - factor) * b + factor

# --- Standardize model names ---
results_df["Model"] = results_df["Model"].str.title()

# --- Identify metric columns dynamically ---
r2_cols = [col for col in results_df.columns if col.startswith("R2")]
rmse_cols = [col for col in results_df.columns if col.startswith("RMSE")]

# --- Melt ---
r2_long = results_df.melt(
    id_vars=["Model", "Dataset"],
    value_vars=r2_cols,
    var_name="Metric_Target",
    value_name="R2"
)
rmse_long = results_df.melt(
    id_vars=["Model", "Dataset"],
    value_vars=rmse_cols,
    var_name="Metric_Target",
    value_name="RMSE"
)

# --- Extract target names ---
r2_long["Target"] = r2_long["Metric_Target"].str.replace("R2 - ", "").str.replace("R2_", "")
rmse_long["Target"] = rmse_long["Metric_Target"].str.replace("RMSE - ", "").str.replace("RMSE_", "")

# --- Compute Mean ---
r2_mean = r2_long.groupby(["Model", "Dataset"], as_index=False)["R2"].mean()
r2_mean["Target"] = "Mean"
rmse_mean = rmse_long.groupby(["Model", "Dataset"], as_index=False)["RMSE"].mean()
rmse_mean["Target"] = "Mean"

r2_long = pd.concat([r2_long, r2_mean], ignore_index=True)
rmse_long = pd.concat([rmse_long, rmse_mean], ignore_index=True)

# --- Normalize RMSE ---
rmse_long["RMSE_norm"] = rmse_long.groupby("Target")["RMSE"].transform(
    lambda x: (x - x.min()) / (x.max() - x.min())
)

# --- Add metric + value columns ---
r2_long["Metric"] = "R²"
r2_long["Value"] = r2_long["R2"]
rmse_long["Metric"] = "Normalized RMSE"
rmse_long["Value"] = rmse_long["RMSE_norm"]

# --- Combine ---
plot_df = pd.concat([r2_long, rmse_long], ignore_index=True)
plot_df["Target_Dataset"] = plot_df["Target"] + " (" + plot_df["Dataset"] + ")"

# --- Get unique targets from the data ---
unique_targets = sorted(plot_df["Target"].unique(), key=lambda x: (x != "Mean", x))

# --- Define base color palette automatically ---
base_palette = sns.color_palette("tab10", n_colors=len(unique_targets))
base_colors = dict(zip(unique_targets, base_palette))

# --- Build full palette with Train = light, Test = dark ---
palette = {}
hue_order = []
for target in unique_targets:
    base = base_colors[target]
    palette[f"{target} (Train)"] = lighten(base, 0.4)
    palette[f"{target} (Test)"] = base
    hue_order.append(f"{target} (Train)")
    hue_order.append(f"{target} (Test)")

# --- Apply categorical ordering to Target_Dataset ---
plot_df["Target_Dataset"] = pd.Categorical(plot_df["Target_Dataset"], categories=hue_order, ordered=True)

# --- Plot ---
sns.set_style("white")
fig, axes = plt.subplots(1, 2, figsize=(14, 10), dpi=400, sharey=True)

for i, metric in enumerate(["R²", "Normalized RMSE"]):
    ax = axes[i]
    subset = plot_df[plot_df["Metric"] == metric].sort_values("Target_Dataset")
    sns.barplot(
        data=subset,
        x="Value",
        y="Model",
        hue="Target_Dataset",
        hue_order=hue_order,
        palette=palette,
        ax=ax,
        dodge=True,
        errorbar=None
    )
    ax.set_title(metric)
    ax.set_xlim(0, 1.05)
    ax.set_xlabel(metric)
    ax.set_ylabel("")
    ax.grid(False)
    ax.tick_params(axis="y", labelsize=9)
    ax.legend_.remove()

# --- Shared legend with correct order ---
handles, labels = axes[0].get_legend_handles_labels()
fig.legend(handles, labels, title="Target", loc="lower center", ncol=4, frameon=False)

# --- Title ---
fig.suptitle("Model Metrics by Target (Train vs Test)", fontsize=16, y=1.02)
plt.tight_layout(rect=[0, 0.07, 1, 0.95])
plt.show()






import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# --- Extract and clean R² and RMSE columns ---
r2_cols = [col for col in results_df.columns if col.startswith("R2")]
rmse_cols = [col for col in results_df.columns if col.startswith("RMSE")]

r2_df = results_df[["Model", "Dataset"] + r2_cols].copy()
rmse_df = results_df[["Model", "Dataset"] + rmse_cols].copy()

# --- Collapse to mean across targets ---
r2_df["R2_mean"] = r2_df[r2_cols].mean(axis=1)
rmse_df["RMSE_mean"] = rmse_df[rmse_cols].mean(axis=1)

# --- Merge back into a summary table ---
summary = pd.merge(r2_df[["Model", "Dataset", "R2_mean"]],
                   rmse_df[["Model", "Dataset", "RMSE_mean"]],
                   on=["Model", "Dataset"])

# --- Pivot: one row per model, split train/test ---
summary_wide = summary.pivot(index="Model", columns="Dataset", values=["R2_mean", "RMSE_mean"])
summary_wide.columns = ['R2_Test', 'R2_Train', 'RMSE_Test', 'RMSE_Train']
summary_wide = summary_wide.reset_index()

# --- Compute ratios and composite score ---
summary_wide["R2_Ratio"] = summary_wide["R2_Test"] / summary_wide["R2_Train"]
summary_wide["RMSE_Ratio"] = summary_wide["RMSE_Test"] / summary_wide["RMSE_Train"]

# Composite score: test R² minus overfit penalty minus RMSE penalty
alpha = 0.001
summary_wide["Composite_Score"] = (
    summary_wide["R2_Test"] 
    - (summary_wide["R2_Train"] - summary_wide["R2_Test"])  # penalize overfit
    - alpha * summary_wide["RMSE_Test"]                      # penalize absolute error
)

# --- Sort by best score ---
summary_wide = summary_wide.sort_values(by="Composite_Score", ascending=False).round(3)

# --- Display table ---
from IPython.display import display
display(summary_wide)

# --- Plot barplot of R² and RMSE test scores ---
plt.figure(figsize=(10, 5))
sns.barplot(data=summary_wide, x="R2_Test", y="Model", color="#1f77b4", label="R² Test")
sns.barplot(data=summary_wide, x="R2_Train", y="Model", color="#aec7e8", label="R² Train", alpha=0.6)
plt.xlabel("R²")
plt.title("Train vs Test R² per Model")
plt.legend()
plt.grid(False)
plt.xlim(0, 1.05)
plt.tight_layout()
plt.show()



# Scatter plot: Train vs Test R²
plt.figure(figsize=(6, 6))
sns.scatterplot(
    data=summary_wide,
    x="R2_Train",
    y="R2_Test",
    hue="Model",
    s=100
)

# Add 1:1 reference line
plt.plot([0, 1], [0, 1], linestyle="--", color="gray", label="Ideal Generalization")

# Annotations
for i, row in summary_wide.iterrows():
    plt.text(row["R2_Train"] + 0.01, row["R2_Test"], row["Model"], fontsize=9)

plt.xlabel("Train R²")
plt.ylabel("Test R²")
plt.title("Train vs. Test R² per Model")
plt.xlim(0, 1.05)
plt.ylim(0, 1.05)
#plt.legend(loc="lower right", frameon=False)
plt.grid(True)
plt.tight_layout()
plt.show()

