# NHANES Machine Learning Pipeline

This project builds a reproducible machine learning pipeline to model and predict health outcomes using the NHANES dataset. It includes scripts for cleaning, preprocessing, training, evaluation, and visualization.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # NHANES XPT data files
â”‚   â”œâ”€â”€ processed/               # Cleaned + preprocessed datasets
â”‚   â””â”€â”€ input/                   # New rows for prediction
â”‚
â”œâ”€â”€ models/                     # Saved trained models
â”œâ”€â”€ summaries/                  # Metrics, residuals, feature importances
â”œâ”€â”€ figures/                    # Saved plots for reporting
â”œâ”€â”€ predictions/                # Predictions for new input
â”œâ”€â”€ data/config/features.yaml   # Feature definitions and metadata
â”‚
â”œâ”€â”€ load_clean.py               # Merges and cleans raw NHANES data
â”œâ”€â”€ summarize_data.py           # Computes missingness and distributions
â”œâ”€â”€ preprocess_model_data.py    # Scales + splits train/test datasets
â”œâ”€â”€ train_models.py             # Trains and tunes regression models
â”œâ”€â”€ evaluate_models.py          # Computes R^2 and RMSE, outputs residuals
â”œâ”€â”€ feature_importance.py       # Extracts feature importances (tree models)
â”œâ”€â”€ generate_figures.py         # Produces key summary plots
â”œâ”€â”€ predict.py                  # Makes predictions on new data
â”œâ”€â”€ run_pipeline.py             # Runs full end-to-end pipeline
â””â”€â”€ README.md                   # Project documentation
```

---

## ğŸ” Pipeline Workflow

Run everything with:
```bash
python run_pipeline.py
```

Or step-by-step:
```bash
python load_clean.py
python summarize_data.py
python preprocess_model_data.py
python train_models.py
python evaluate_models.py
python feature_importance.py
python generate_figures.py
```

---

## ğŸ§  Models Trained
- **Random Forest**
- **Gradient Boosting**
- **K-Nearest Neighbors (KNN)**
- **Ridge Regression**
- **Support Vector Regression (SVR)**

All models use a `Pipeline` with preprocessing (`StandardScaler`, `OneHotEncoder`) and multi-output regressors.

---

## ğŸ“Š Outputs
- `summaries/metrics.csv`: RÂ² and RMSE per model and target
- `summaries/residuals.csv`: residuals per prediction
- `summaries/feature_importances.csv`: mean importance across targets
- `figures/`: plots of model performance and residuals
- `predictions/predictions.csv`: outputs from `predict.py`

---

## âœ¨ Example Usage

Predict on new data:
```bash
python predict.py
```

Edit `data/input/input.csv` to provide rows for prediction.

---

## âš™ï¸ Configurable Features
Defined in `data/config/features.yaml`, you can:
- Mark variables as `numeric`, `categorical`, or `target`
- Easily toggle which features and targets are used

---


---

## âš™ï¸ `load_clean.py` â€“ Data Cleaning & Preparation

This script reads, cleans, and merges NHANES data according to rules defined in `features.yaml`, then outputs a cleaned CSV ready for modeling.

### ğŸ§¼ Key Steps Performed:

1. **Load selected features** from `features.yaml`
2. **Merge multiple `.xpt.txt` files** on `SEQN`
3. **Rename columns** to friendly names (e.g., `BMXBMI` â†’ `bmi`)
4. **Replace special missing values** (e.g., 7, 9, 777, 999) with `pd.NA`
5. **Remove extrema** for numeric features flagged with `drop_extrema: true`
6. **Map categorical values** to human-readable labels (e.g., `1` â†’ `Male`)
7. **Drop rows with missing target values** to ensure valid multi-output regression input
8. **Save final DataFrame** to `../data/processed/clean_data.csv`

---

## ğŸ“Š `summarize_data.py` â€“ Exploratory Summary

This script provides a quick overview of the cleaned dataset:

- Number of rows and columns
- Count and percentage of missing values per column
- Summary statistics for numeric variables
- Value counts for categorical variables

Useful for sanity checks before modeling.

---

## ğŸ”§ Configuration via `features.yaml`

All variables used in the pipeline are defined in `features.yaml` and include:

- `name`: target name for modeling
- `source`: original NHANES code
- `file`: raw data file
- `type`: `numeric` or `categorical`
- `role`: `feature` or `target`
- `drop_extrema`: optional, for numeric range cleaning
- `map`: optional, dictionary to map codes to labels

Example:

```yaml
- name: sex
  source: RIAGENDR
  file: DEMO_I
  type: categorical
  role: feature
  map:
    1: "Male"
    2: "Female"

---

## ğŸ“Œ Requirements
- Python 3.8+
- pandas, numpy, scikit-learn, seaborn, matplotlib, joblib, pyyaml

---

## âœ… Next Steps
- Add Tableau dashboards using `summaries/` and `figures/`
- Extend to other NHANES cycles
- Package into a lightweight API or Streamlit app

---

## Author
[Your Name Here]

MIT License

