# NHANES Machine Learning Pipeline

This project builds a reproducible machine learning pipeline to model and predict health outcomes using the NHANES dataset. It supports end-to-end tasks: loading, cleaning, preprocessing, training, evaluation, and reporting.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # NHANES XPT data files
â”‚   â”œâ”€â”€ processed/                # Cleaned + preprocessed datasets
â”‚   â”œâ”€â”€ input/                    # New rows for prediction
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ features.yaml         # Feature definitions and metadata
â”‚
â”œâ”€â”€ models/                       # Saved trained models
â”œâ”€â”€ summaries/                    # Metrics, residuals, feature importances
â”œâ”€â”€ figures/                      # Saved plots for reporting
â”œâ”€â”€ predictions/                  # Predictions for new input
â”‚
â”œâ”€â”€ load_clean.py                # Merges, renames, cleans raw data
â”œâ”€â”€ summarize_data.py            # Missingness + EDA summaries
â”œâ”€â”€ preprocess_model_data.py     # Preprocessing and train/test split
â”œâ”€â”€ train_models.py              # Model training and tuning
â”œâ”€â”€ evaluate_models.py           # RÂ², RMSE, residuals
â”œâ”€â”€ feature_importance.py        # Tree-based importance extraction
â”œâ”€â”€ generate_figures.py          # Summary plots and charts
â”œâ”€â”€ predict.py                   # Run model on new input
â”œâ”€â”€ run_pipeline.py              # Run full pipeline in sequence
â””â”€â”€ README.md                    # Project documentation
```

---

## ğŸ” Pipeline Workflow

Run the full pipeline:

```bash
python run_pipeline.py
```

Or step-by-step:

```bash
python load_clean.py
python summarize_data.py
python preprocess_model_data.py
python train_models.py
python evaluate_models.py
python feature_importance.py
python generate_figures.py
```

---

## âš™ï¸ `load_clean.py` â€“ Data Cleaning

This script prepares raw NHANES data for modeling. It performs:

1. Feature selection via `features.yaml`
2. Merge of multiple `.xpt.txt` files on `SEQN`
3. Renaming to human-readable feature names
4. Invalid value replacement (e.g., 7, 9, 777 â†’ `pd.NA`)
5. Extrema filtering for numeric features
6. Categorical mapping (e.g., `1 â†’ Male`)
7. Dropping rows with missing target values, required for multi-output models
8. CSV export to `data/processed/clean_data.csv`

---

## ğŸ“Š `summarize_data.py` â€“ Data Exploration

This script provides:

- Missing value counts and percentages
- Descriptive stats for numeric features
- Value counts for categorical features

Ideal for pre-modeling checks and understanding data quality.

---

## ğŸ“„ `features.yaml` â€“ Feature Configuration

Located in `data/config/`, this file controls:

- Feature names, types, and sources
- Role in modeling (`feature` or `target`)
- Optional extrema filtering (`drop_extrema: true`)
- Optional value mappings

Example:

```yaml
- name: sex
  source: RIAGENDR
  file: DEMO_I
  type: categorical
  role: feature
  map:
    1: "Male"
    2: "Female"
```

---

## ğŸ“ˆ Models Supported

- Random Forest
- Gradient Boosting
- K-Nearest Neighbors (KNN)
- Ridge Regression
- Support Vector Regression (SVR)

All models use a `Pipeline` with preprocessing (scaling, encoding) and support multi-output regression (predicting multiple targets simultaneously).

---

## ğŸ“¤ Outputs

- `summaries/metrics.csv` â€“ RÂ² and RMSE per model and target
- `summaries/residuals.csv` â€“ prediction residuals
- `summaries/feature_importances.csv` â€“ tree-based importances
- `figures/` â€“ plots of model performance and residuals
- `predictions/predictions.csv` â€“ predictions for new data

---

## ğŸ§  Example: Predict on New Data

Update `data/input/input.csv`, then run:

```bash
python predict.py
```

Predictions will be saved to `predictions/predictions.csv`.

---

## âœ… Requirements

- Python 3.8+
- Packages: `pandas`, `numpy`, `scikit-learn`, `pyreadstat`, `pyyaml`, `matplotlib`, `seaborn`, `joblib`

Install via:

```bash
pip install -r requirements.txt
```

---

## ğŸ§­ Next Steps

- Add Tableau dashboard from `summaries/` and `figures/`
- Extend to additional NHANES cycles
- Package into a Streamlit app or lightweight API

---

## ğŸ“‡ License

MIT License â€” free to use, modify, and share.

---

## ğŸ‘¤ Author

[Your Name Here]
